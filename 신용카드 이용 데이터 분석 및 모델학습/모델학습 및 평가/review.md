### 3개 모델 성능 비교
- logisticregression: 0.8615
- SGDclassifier: 0.8538
- lightGBM: 0.8714

### LightGBM 성능 비교
**1. 첫 번째 모델 평가 결과 (초기 정확도 최적화, 클래스 가중치/F1-weighted 튜닝 이전)**
    - Model Accuracy on Test Set: 0.8854
    - Model F1-weighted Score on Test Set: 약 0.88

| Segment | Precision | Recall | F1-Score | Support |
| :------ | :-------- | :----- | :------- | :------ |
| A       | 0.64      | 0.59   | 0.61     | 6998    |
| B       | 0.81      | 0.79   | 0.80     | 1037    |
| C       | 0.71      | 0.55   | 0.62     | 918648  |
| D       | 0.66      | 0.59   | 0.63     | 2514543 |
| E       | 0.93      | 0.96   | 0.95     | 13838774|
| **macro avg** | 0.75 | 0.70 | 0.72 | 17280000 |
| **weighted avg** | 0.88 | 0.89 | 0.88 | 17280000 |

* **해석:**
* 전체 `Accuracy`는 높았지만, `Segment A, C, D`와 같이 소수이거나 예측이 어려운 클래스에서 `Recall` (실제 해당 클래스 고객을 놓치는 비율)이 상대적으로 낮았습니다 (55%~59% 수준). 이는 다수 클래스 `E`의 높은 성능에 크게 의존한 결과입니다.

---

**2. 두 번째 모델 평가 결과 (클래스 가중치 적용 및 F1-weighted 최적화 이후)**
    * **Model Accuracy on Test Set: 0.8373** (이전보다 하락)
    * **Model F1-weighted Score on Test Set: 0.8515** (이전보다 하락)

| Segment | Precision | Recall | F1-Score | Support |
| :------ | :-------- | :----- | :------- | :------ |
| A       | 0.44      | **0.98** | 0.61     | 6998    |
| B       | 0.68      | **0.98** | 0.80     | 1037    |
| C       | 0.50      | **0.79** | 0.61     | 918648  |
| D       | 0.51      | **0.72** | 0.60     | 2514543 |
| E       | **0.97** | 0.86   | 0.91     | 13838774|
| **macro avg** | 0.62 | 0.87 | 0.71 | 17280000 |
| **weighted avg** | 0.88 | 0.84 | 0.85 | 17280000 |

* **해석:**
    * `Accuracy`와 `F1-weighted Score`는 전체적으로 하락했습니다.
    * 하지만 **소수 클래스들의 `Recall`이 크게 개선**되었습니다. 특히 `Segment A`와 `B`의 `Recall`은 거의 100%에 육박하게 상승했습니다. 이는 모델이 소수 클래스들을 놓치지 않고 더 잘 찾아내도록 학습되었음을 의미합니다.
    * 이러한 `Recall` 개선은 다수 클래스 `E`의 `Recall`이 0.96에서 0.86으로 하락한 대가로 얻어진 것입니다. 다수 클래스의 성능 하락이 전체 정확도 하락에 직접적인 영향을 주었습니다.
